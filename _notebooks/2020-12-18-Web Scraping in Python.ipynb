{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Easy Web Scraping with Python\"\n",
    "> \"And build a data application\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- hide_binder_badge: True\n",
    "- hide_colab_badge: True\n",
    "- comments: true\n",
    "- author: Samuel Oranyeli\n",
    "- categories: [python, streamlit, requests-html, requests, Pandas]\n",
    "- image: images/some_folder/your_image.png\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: \"web scraping\"\n",
    "- metadata_key2: \"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is partly motivated by an [article](https://www.betterdatascience.com/web-scraping-with-r-easier-than-python/) published by [Dario Radecic](https://www.betterdatascience.com/author/betterdatascience_onouc8/) - the article is a good read. \n",
    "\n",
    "The aim here is to show how to scrape pages easily in Python and share your results. We will be using two packages : [requests-html](https://requests-html.kennethreitz.org/) for the web scraping, and [streamlit](https://www.streamlit.io/) to build a data application. \n",
    "\n",
    "Our source for the scraping is [books.toscrape.com](http://books.toscrape.com/). It is a good place to practise web scraping.\n",
    "\n",
    "Our goal - Get the title, book url, thumbnail url, rating, price, and availability of each book per genre on the website. Roughly a thousand books. A sample image of one of the books is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![webscraping.png](Images/webscraping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To effectively scrape web pages, one needs to understand a bit of [html](https://www.w3schools.com/html/) and [css](https://www.w3schools.com/html/html_css.asp). [W3Schools](https://www.w3schools.com/) is a good place to learn the fundamentals; we will not be dwelling on that here, just how to use it.\n",
    "\n",
    "You can check the output of the web scraping [here](https://safe-refuge-85400.herokuapp.com/). You can access the complete [python file](https://github.com/samukweku/data-wrangling-blog/blob/master/_notebooks/Data_files/webscraper.py) as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Web Scraping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[requests-html](https://requests-html.kennethreitz.org/) makes web scraping easy. It supports both [css-selectors](https://www.w3schools.com/cssref/css_selectors.asp) and [xpath](https://www.w3schools.com/xml/xpath_intro.asp); we will be using [css-selectors](https://www.w3schools.com/cssref/css_selectors.asp). Let's look at how to scrape the book titles in the *Travel* category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It's Only the Himalayas\",\n",
       " 'Full Moon over Noah’s Ark: An Odyssey to Mount Ararat and Beyond',\n",
       " 'See America: A Celebration of Our National Parks & Treasured Sites',\n",
       " 'Vagabonding: An Uncommon Guide to the Art of Long-Term World Travel',\n",
       " 'Under the Tuscan Sun',\n",
       " 'A Summer In Europe',\n",
       " 'The Great Railway Bazaar',\n",
       " 'A Year in Provence (Provence #1)',\n",
       " 'The Road to Little Dribbling: Adventures of an American in Britain (Notes From a Small Island #2)',\n",
       " 'Neither Here nor There: Travels in Europe',\n",
       " '1,000 Places to See Before You Die']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "\n",
    "# url for travel section:\n",
    "url = \"http://books.toscrape.com/catalogue/category/books/travel_2/index.html\"\n",
    "\n",
    "# access data from url:\n",
    "webpage = session.get(url)\n",
    "\n",
    "titles = [element.attrs[\"title\"] for element in webpage.html.find(\"h3>a\")]\n",
    "\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty easy and straightforward. The key part is getting the [css-selectors](https://www.w3schools.com/cssref/css_selectors.asp) right. \n",
    "\n",
    "Let's write a function that gets the title, urls, and other details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def data_extract(genre):\n",
    "    # pull data from specific webpage\n",
    "    webpage = genre_urls.get(genre)\n",
    "    webpage = session.get(webpage)\n",
    "    \n",
    "    urls = [element.attrs[\"href\"].strip(\"../\")\n",
    "            for element in webpage.html.find(\"div.image_container>a\")\n",
    "           ]\n",
    "\n",
    "    titles = [element.attrs[\"title\"] for element in webpage.html.find(\"h3>a\")]\n",
    "\n",
    "    imgs = [element.attrs[\"src\"].strip(\"../\")\n",
    "            for element in webpage.html.find(\"div.image_container>a>img\")\n",
    "           ]\n",
    "\n",
    "    ratings = [element.attrs[\"class\"][-1] \n",
    "               for element in webpage.html.find(\"p.star-rating\")\n",
    "              ]\n",
    "\n",
    "    prices = [element.text for element in webpage.html.find(\"p.price_color\")]\n",
    "\n",
    "    availability = [element.text for element in webpage.html.find(\"p.instock\")]\n",
    "\n",
    "    data = dict(\n",
    "        Title = titles,\n",
    "        URL = urls,\n",
    "        Source_Image = imgs,\n",
    "        Rating = ratings,\n",
    "        Price = prices,\n",
    "        Availability = availability,\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above pulls in the data and returns a [Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html) dataframe.\n",
    "\n",
    "What's left is a pairing of the categories and the urls for each category for the entire website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"http://books.toscrape.com/\"\n",
    "main_page = session.get(main_url)\n",
    "\n",
    "# the css-selector helps pull out the links for all the categories (travel, horror, crime, ...)\n",
    "navlinks = \"div.side_categories>ul.nav.nav-list>li>ul>li>a\"\n",
    "\n",
    "# get the categories\n",
    "genres = [element.text for element in main_page.html.find(navlinks)]\n",
    "\n",
    "# get the actual urls for each category\n",
    "genre_urls = [f\"{main_url}/{element.attrs['href']}\" \n",
    "             for element in main_page.html.find(navlinks)\n",
    "            ]\n",
    "\n",
    "# pair the category with the url\n",
    "genre_urls = dict(zip(genres, genre_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily apply the *data_extract* function to any genre to get the entire details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Source_Image</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "      <th>Availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>its-only-the-himalayas_981/index.html</td>\n",
       "      <td>media/cache/27/a5/27a53d0bb95bdd88288eaf66c923...</td>\n",
       "      <td>Two</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Moon over Noah’s Ark: An Odyssey to Mount...</td>\n",
       "      <td>full-moon-over-noahs-ark-an-odyssey-to-mount-a...</td>\n",
       "      <td>media/cache/57/77/57770cac1628f4407636635f4b85...</td>\n",
       "      <td>Four</td>\n",
       "      <td>£49.43</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>See America: A Celebration of Our National Par...</td>\n",
       "      <td>see-america-a-celebration-of-our-national-park...</td>\n",
       "      <td>media/cache/9a/7e/9a7e63f12829df4b43b31d110bf3...</td>\n",
       "      <td>Three</td>\n",
       "      <td>£48.87</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vagabonding: An Uncommon Guide to the Art of L...</td>\n",
       "      <td>vagabonding-an-uncommon-guide-to-the-art-of-lo...</td>\n",
       "      <td>media/cache/d5/bf/d5bf0090470b0b8ea46d9c166f78...</td>\n",
       "      <td>Two</td>\n",
       "      <td>£36.94</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Under the Tuscan Sun</td>\n",
       "      <td>under-the-tuscan-sun_504/index.html</td>\n",
       "      <td>media/cache/98/c2/98c2e95c5fd1a4e7cd5f2b63c528...</td>\n",
       "      <td>Three</td>\n",
       "      <td>£37.33</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Summer In Europe</td>\n",
       "      <td>a-summer-in-europe_458/index.html</td>\n",
       "      <td>media/cache/4e/15/4e15150388702ebca2c5a523ac27...</td>\n",
       "      <td>Two</td>\n",
       "      <td>£44.34</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Great Railway Bazaar</td>\n",
       "      <td>the-great-railway-bazaar_446/index.html</td>\n",
       "      <td>media/cache/76/de/76de41867f323d7f1f4fbe2fdfc1...</td>\n",
       "      <td>One</td>\n",
       "      <td>£30.54</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Year in Provence (Provence #1)</td>\n",
       "      <td>a-year-in-provence-provence-1_421/index.html</td>\n",
       "      <td>media/cache/db/46/db46159b05faa5d95262112bf9c2...</td>\n",
       "      <td>Four</td>\n",
       "      <td>£56.88</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Road to Little Dribbling: Adventures of an...</td>\n",
       "      <td>the-road-to-little-dribbling-adventures-of-an-...</td>\n",
       "      <td>media/cache/e0/4f/e04f8eda2a2fa947aec17640202d...</td>\n",
       "      <td>One</td>\n",
       "      <td>£23.21</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Neither Here nor There: Travels in Europe</td>\n",
       "      <td>neither-here-nor-there-travels-in-europe_198/i...</td>\n",
       "      <td>media/cache/06/81/0681530a7bc301caf5c3257e1b0f...</td>\n",
       "      <td>Three</td>\n",
       "      <td>£38.95</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1,000 Places to See Before You Die</td>\n",
       "      <td>1000-places-to-see-before-you-die_1/index.html</td>\n",
       "      <td>media/cache/d7/0f/d70f7edd92705c45a82118c3ff6c...</td>\n",
       "      <td>Five</td>\n",
       "      <td>£26.08</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                             It's Only the Himalayas   \n",
       "1   Full Moon over Noah’s Ark: An Odyssey to Mount...   \n",
       "2   See America: A Celebration of Our National Par...   \n",
       "3   Vagabonding: An Uncommon Guide to the Art of L...   \n",
       "4                                Under the Tuscan Sun   \n",
       "5                                  A Summer In Europe   \n",
       "6                            The Great Railway Bazaar   \n",
       "7                    A Year in Provence (Provence #1)   \n",
       "8   The Road to Little Dribbling: Adventures of an...   \n",
       "9           Neither Here nor There: Travels in Europe   \n",
       "10                 1,000 Places to See Before You Die   \n",
       "\n",
       "                                                  URL  \\\n",
       "0               its-only-the-himalayas_981/index.html   \n",
       "1   full-moon-over-noahs-ark-an-odyssey-to-mount-a...   \n",
       "2   see-america-a-celebration-of-our-national-park...   \n",
       "3   vagabonding-an-uncommon-guide-to-the-art-of-lo...   \n",
       "4                 under-the-tuscan-sun_504/index.html   \n",
       "5                   a-summer-in-europe_458/index.html   \n",
       "6             the-great-railway-bazaar_446/index.html   \n",
       "7        a-year-in-provence-provence-1_421/index.html   \n",
       "8   the-road-to-little-dribbling-adventures-of-an-...   \n",
       "9   neither-here-nor-there-travels-in-europe_198/i...   \n",
       "10     1000-places-to-see-before-you-die_1/index.html   \n",
       "\n",
       "                                         Source_Image Rating   Price  \\\n",
       "0   media/cache/27/a5/27a53d0bb95bdd88288eaf66c923...    Two  £45.17   \n",
       "1   media/cache/57/77/57770cac1628f4407636635f4b85...   Four  £49.43   \n",
       "2   media/cache/9a/7e/9a7e63f12829df4b43b31d110bf3...  Three  £48.87   \n",
       "3   media/cache/d5/bf/d5bf0090470b0b8ea46d9c166f78...    Two  £36.94   \n",
       "4   media/cache/98/c2/98c2e95c5fd1a4e7cd5f2b63c528...  Three  £37.33   \n",
       "5   media/cache/4e/15/4e15150388702ebca2c5a523ac27...    Two  £44.34   \n",
       "6   media/cache/76/de/76de41867f323d7f1f4fbe2fdfc1...    One  £30.54   \n",
       "7   media/cache/db/46/db46159b05faa5d95262112bf9c2...   Four  £56.88   \n",
       "8   media/cache/e0/4f/e04f8eda2a2fa947aec17640202d...    One  £23.21   \n",
       "9   media/cache/06/81/0681530a7bc301caf5c3257e1b0f...  Three  £38.95   \n",
       "10  media/cache/d7/0f/d70f7edd92705c45a82118c3ff6c...   Five  £26.08   \n",
       "\n",
       "   Availability  \n",
       "0      In stock  \n",
       "1      In stock  \n",
       "2      In stock  \n",
       "3      In stock  \n",
       "4      In stock  \n",
       "5      In stock  \n",
       "6      In stock  \n",
       "7      In stock  \n",
       "8      In stock  \n",
       "9      In stock  \n",
       "10     In stock  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view all the details for the Travel category\n",
    "data_extract(\"Travel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data extraction is complete. Next up is building an easy to use **[web application](https://safe-refuge-85400.herokuapp.com/)**. Enter [streamlit](https://www.streamlit.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:26:23.474681Z",
     "iopub.status.busy": "2020-10-31T01:26:23.474464Z",
     "iopub.status.idle": "2020-10-31T01:26:23.477682Z",
     "shell.execute_reply": "2020-10-31T01:26:23.477047Z",
     "shell.execute_reply.started": "2020-10-31T01:26:23.474658Z"
    }
   },
   "source": [
    "## **Sharing Data Apps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[streamlit](https://www.streamlit.io/) really makes building data apps easy, with a few lines of code. \n",
    "\n",
    "The code below is basic, but shows the power of streamlit. All we have to do is :\n",
    "\n",
    "- Import streamlit, \n",
    "- give our application a title, \n",
    "- add our web scraping code, \n",
    "- add a [sidebar](https://docs.streamlit.io/en/stable/api.html#add-widgets-to-sidebar) to select genres, and finally\n",
    "- add a line of code to show the results. The entire code is listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import streamlit and other libraries\n",
    "import streamlit as st\n",
    "from requests_html import HTMLSession\n",
    "import pandas as pd\n",
    "\n",
    "# give our application a title\n",
    "st.title(\"Real-time web scraper with Python\")\n",
    "\n",
    "\n",
    "# add our web scraping code\n",
    "session = HTMLSession()\n",
    "main_url = \"http://books.toscrape.com/\"\n",
    "main_page = session.get(main_url)\n",
    "\n",
    "navlinks = \"div.side_categories>ul.nav.nav-list>li>ul>li>a\"\n",
    "genres = [element.text for element in main_page.html.find(navlinks)]\n",
    "list_urls = [\n",
    "    f\"{main_url}/{element.attrs['href']}\" for element in main_page.html.find(navlinks)\n",
    "]\n",
    "genre_urls = dict(zip(genres, list_urls))\n",
    "\n",
    "\n",
    "@st.cache\n",
    "def data_extract(genre):\n",
    "    webpage = genre_urls.get(genre)\n",
    "    webpage = session.get(webpage)\n",
    "    urls = [\n",
    "        element.attrs[\"href\"].strip(\"../\")\n",
    "        for element in webpage.html.find(\"div.image_container>a\")\n",
    "    ]\n",
    "\n",
    "    titles = [element.attrs[\"title\"] for element in webpage.html.find(\"h3>a\")]\n",
    "\n",
    "    imgs = [\n",
    "        element.attrs[\"src\"].strip(\"../\")\n",
    "        for element in webpage.html.find(\"div.image_container>a>img\")\n",
    "    ]\n",
    "\n",
    "    ratings = [\n",
    "        element.attrs[\"class\"][-1] for element in webpage.html.find(\"p.star-rating\")\n",
    "    ]\n",
    "\n",
    "    prices = [element.text for element in webpage.html.find(\"p.price_color\")]\n",
    "\n",
    "    availability = [element.text for element in webpage.html.find(\"p.instock\")]\n",
    "\n",
    "    data = dict(\n",
    "        Title=titles,\n",
    "        URL=urls,\n",
    "        SourceImage=imgs,\n",
    "        Rating=ratings,\n",
    "        Price=prices,\n",
    "        Availability=availability,\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(data).to_markdown(index=False)\n",
    "\n",
    "\n",
    "# add a sidebar to select genre\n",
    "option = st.sidebar.selectbox(\"Genres\", genres)\n",
    "\n",
    "# add a line of code to show the result\n",
    "st.markdown(data_extract(option), unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy. Of course, this is a very simple application; you can do so much more with streamlit. Have a look at the [streamlit gallery](https://www.streamlit.io/gallery) for inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T08:59:52.887765Z",
     "iopub.status.busy": "2020-10-31T08:59:52.887501Z",
     "iopub.status.idle": "2020-10-31T08:59:52.893435Z",
     "shell.execute_reply": "2020-10-31T08:59:52.892724Z",
     "shell.execute_reply.started": "2020-10-31T08:59:52.887738Z"
    }
   },
   "source": [
    "## **Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping and building data applications are easy to do in Python. Hopefully, this article gives you an idea of how to achieve this, the rest is up to you to go far and beyond."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pyjanitor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6988fdc349cebf087982060ba0d703f44fccde5c0343683aa63b0b79fe3c156"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
